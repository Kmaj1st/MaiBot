[inner]
version = "1.8.2"

[[api_providers]]
name = "SiliconFlow"
base_url = "https://api.siliconflow.cn/v1"
api_key = "SF_KEY"
client_type = "openai"
max_retry = 3
timeout = 15
retry_interval = 3

[[api_providers]]
name = "xAI"
base_url = "https://api.x.ai/v1"
api_key = "XAI_KEY"
client_type = "openai"
max_retry = 3
timeout = 15
retry_interval = 5

[[api_providers]]
name = "RinkoAI"
base_url = "https://rinkoai.com/v1"
api_key = "RK_KEY"
client_type = "openai"
max_retry = 1
timeout = 30
retry_interval = 3

[[models]]
model_identifier = "deepseek-ai/DeepSeek-V3.2-Exp"
name = "deepseek-ai/DeepSeek-V3.2-Exp"
api_provider = "SiliconFlow"
price_in = 2.0
price_out = 8.0

[[models]]
model_identifier = "deepseek-ai/DeepSeek-V3.1-Terminus"
name = "deepseek-ai/DeepSeek-V3.1-Terminus"
api_provider = "SiliconFlow"
price_in = 4
price_out = 12

[[models]]
model_identifier = "deepseek-ai/DeepSeek-R1"
name = "deepseek-ai/DeepSeek-R1"
api_provider = "SiliconFlow"
price_in = 4
price_out = 16

[[models]]
model_identifier = "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B"
name = "deepseek-r1-distill-qwen-32b"
api_provider = "SiliconFlow"
price_in = 4.0
price_out = 16.0

[[models]]
model_identifier = "Qwen/Qwen3-8B"
name = "Qwen/Qwen3-8B"
api_provider = "SiliconFlow"
price_in = 0
price_out = 0

[[models]]
model_identifier = "Qwen/Qwen3-14B"
name = "Qwen/Qwen3-14B"
api_provider = "SiliconFlow"
price_in = 0.5
price_out = 2.0

[[models]]
model_identifier = "Qwen/Qwen3-VL-30B-A3B-Instruct"
name = "Qwen/Qwen3-VL-30B-A3B-Instruct"
api_provider = "SiliconFlow"
price_in = 0.7
price_out = 2.8

[[models]]
model_identifier = "Qwen/Qwen3-VL-32B-Instruct"
name = "Qwen/Qwen3-VL-32B-Instruct"
api_provider = "SiliconFlow"
price_in = 0.7
price_out = 2.8

[[models]]
model_identifier = "Qwen/Qwen2.5-VL-72B-Instruct"
name = "Qwen/Qwen2.5-VL-72B-Instruct"
api_provider = "SiliconFlow"
price_in = 4.13
price_out = 4.13

[[models]]
model_identifier = "Qwen/Qwen3-Next-80B-A3B-Instruct"
name = "Qwen/Qwen3-Next-80B-A3B-Instruct"
api_provider = "SiliconFlow"
price_in = 1
price_out = 4

[[models]]
model_identifier = "FunAudioLLM/SenseVoiceSmall"
name = "FunAudioLLM/SenseVoiceSmall"
api_provider = "SiliconFlow"
price_in = 0
price_out = 0

[[models]]
model_identifier = "TeleAI/TeleSpeechASR"
name = "TeleAI/TeleSpeechASR"
api_provider = "SiliconFlow"
price_in = 0
price_out = 0

[[models]]
model_identifier = "BAAI/bge-m3"
name = "BAAI/bge-m3"
api_provider = "SiliconFlow"
price_in = 0
price_out = 0

[[models]]
model_identifier = "moonshotai/Kimi-K2-Instruct"
name = "moonshotai-Kimi-K2-Instruct"
api_provider = "SiliconFlow"
price_in = 4.0
price_out = 16.0

[[models]]
model_identifier = "grok-4-1-fast-reasoning"
name = "grok-4-1-fast-reasoning"
api_provider = "xAI"
price_in = 1.5
price_out = 4

[[models]]
model_identifier = "grok-4-1-fast-non-reasoning"
name = "grok-4-1-fast-non-reasoning"
api_provider = "xAI"
price_in = 1.5
price_out = 4

[model_task_config.utils] # 在麦麦的一些组件中使用的模型，例如表情包模块，取名模块，关系模块，麦麦的情绪变化等，是麦麦必须的模型
model_list = ["deepseek-ai/DeepSeek-V3.2-Exp", "deepseek-ai/DeepSeek-V3.1-Terminus"] # 使用的模型列表，每个子项对应上面的模型名称(name)
temperature = 0.2                        # 模型温度，新V3建议0.1-0.3
max_tokens = 2048                         # 最大输出token数
slow_threshold = 15.0                     # 慢请求阈值（秒），模型等待回复时间超过此值会输出警告日志

[model_task_config.utils_small] # 在麦麦的一些组件中使用的小模型，消耗量较大，建议使用速度较快的小模型
model_list = ["Qwen/Qwen3-8B", "Qwen/Qwen3-Next-80B-A3B-Instruct"]
temperature = 0.7
max_tokens = 2048
slow_threshold = 10.0

[model_task_config.tool_use] #工具调用模型，需要使用支持工具调用的模型
model_list = ["Qwen/Qwen3-8B", "Qwen/Qwen3-Next-80B-A3B-Instruct"]
temperature = 0.7
max_tokens = 800
slow_threshold = 10.0

[model_task_config.replyer] # 首要回复模型，还用于表达器和表达方式学习
model_list = ["grok-4-1-fast-non-reasoning", "deepseek-ai/DeepSeek-V3.2-Exp"]
temperature = 0.3                        # 模型温度，新V3建议0.1-0.3
max_tokens = 2048
slow_threshold = 25.0

[model_task_config.planner] #决策：负责决定麦麦该什么时候回复的模型
model_list = ["deepseek-ai/DeepSeek-V3.2-Exp", "grok-4-1-fast-reasoning"]
temperature = 0.3
max_tokens = 800
slow_threshold = 12.0

[model_task_config.vlm] # 图像识别模型
model_list = [  "Qwen/Qwen3-VL-32B-Instruct", 
                "Qwen/Qwen3-VL-30B-A3B-Instruct", 
                "Qwen/Qwen2.5-VL-72B-Instruct", 
                "Qwen/Qwen3-Next-80B-A3B-Instruct", 
                "grok-4-1-fast-non-reasoning"]
max_tokens = 256
slow_threshold = 15.0

[model_task_config.voice] # 语音识别模型
model_list = ["FunAudioLLM/SenseVoiceSmall", "TeleAI/TeleSpeechASR"]

# 嵌入模型
[model_task_config.embedding]
model_list = ["BAAI/bge-m3"]

# ------------LPMM知识库模型------------

[model_task_config.lpmm_entity_extract] # 实体提取模型
model_list = ["deepseek-ai/DeepSeek-V3.2-Exp"]
temperature = 0.2
max_tokens = 800
slow_threshold = 20.0

[model_task_config.lpmm_rdf_build] # RDF构建模型
model_list = ["deepseek-ai/DeepSeek-V3.2-Exp"]
temperature = 0.2
max_tokens = 800
slow_threshold = 20.0

[model_task_config.lpmm_qa] # 问答模型
model_list = ["deepseek-ai/DeepSeek-V3.2-Exp"]
temperature = 0.7
max_tokens = 800
slow_threshold = 20.0
